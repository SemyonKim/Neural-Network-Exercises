{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f3PgVXAn6Vz0",
        "yz_T6dFIgiZK",
        "_h-DkN0p6V0y",
        "8mUCmL206V1b",
        "Og5KIm0b6V2X",
        "vRmPpO3O6V3X",
        "f8FjgSVm6V4W",
        "EtfglgVy6V5O",
        "-o0-swCV6V6B",
        "G_xfhOg86V7D"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3PgVXAn6Vz0"
      },
      "source": [
        "# Introduction to Keras — Lab Objectives\n",
        "\n",
        "### Goals of the lab work:\n",
        "- Understand the interface of layers used in building neural networks  \n",
        "- Learn how to train neural networks effectively  \n",
        "- Explore the impact of network depth, normalization, and regularization on performance  \n",
        "- Compare different optimizers to evaluate accuracy and convergence speed  \n",
        "\n",
        "---\n",
        "\n",
        "### Structure of the lab (Tasks 1–7):\n",
        "1. **Single-layer network (baseline):** Establish a starting point with ~92–93% accuracy.  \n",
        "2. **Two-layer network:** Demonstrate how adding hidden layers improves accuracy (~97.6%).  \n",
        "3. **Three-layer network:** Further increase accuracy (~97.9%), showing diminishing returns.  \n",
        "4. **Normalization layers (BatchNorm, Dropout, L2):** Improve convergence speed and stability, with accuracy ~98.1%.  \n",
        "5. **Deep fully connected network:** Achieve ~98.3% accuracy using multiple dense layers, dropout, and batch normalization.  \n",
        "6. **Network with one convolutional layer:** Introduce convolution for image data, reaching ~98.34% accuracy and faster convergence.  \n",
        "7. **Optimizer comparison:** Evaluate SGD, Momentum, NAG, AdaGrad, Adadelta, RMSprop, and Adam.  \n",
        "   - **Best accuracy:** Adadelta (~98.3%)  \n",
        "   - **Fastest convergence:** Adadelta  \n",
        "\n",
        "---\n",
        "### Interpretive Note:\n",
        "This lab progresses from simple architectures to deeper and more complex models, illustrating how each design choice (layers, normalization, regularization, optimizers) affects accuracy, loss, and training dynamics. By the end, you will have a clear understanding of how to build and optimize neural networks in Keras for image classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Setup"
      ],
      "metadata": {
        "id": "yz_T6dFIgiZK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA0SxiFs6V0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3bb30cb-50b9-4651-90d8-f06df4e8400c"
      },
      "source": [
        "# Keras Lab Work\n",
        "# Author: Semyon Kim\n",
        "\n",
        "# --- Imports ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "# Keras modules\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# --- Reproducibility ---\n",
        "np.random.seed(123)\n",
        "\n",
        "# --- Version Check ---\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h-DkN0p6V0y"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_6Mx6SF6V04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "f2e6b56b-d49d-4362-b691-ba53d1cf8dd5",
        "collapsed": true
      },
      "source": [
        "# --- Load MNIST dataset ---\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# --- Reshape data ---\n",
        "# Keras expects input shape (channels, height, width) for Conv2D\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "\n",
        "# --- Normalize pixel values ---\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# --- One-hot encode labels ---\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# --- Visualize a sample ---\n",
        "index = 1238\n",
        "plt.imshow(X_train[index, 0, :, :], cmap=\"gray\")\n",
        "plt.title(f\"Sample digit (label: {np.argmax(Y_train[index])})\")\n",
        "plt.show()\n",
        "\n",
        "# --- Inspect sample values ---\n",
        "print(\"Pixel max:\", np.max(X_train[index,0,:,:]))\n",
        "print(\"Pixel min:\", np.min(X_train[index,0,:,:]))\n",
        "print(\"Pixel dtype:\", X_train.dtype)\n",
        "print(\"One-hot label:\", Y_train[index])\n",
        "print(\"Numeric label:\", np.argmax(Y_train[index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7EASlB1IgrIDSVB2IIn/Az4qhDnlNUeAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.0 0.0 float32\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mUCmL206V1b"
      },
      "source": [
        "## Task 1 (1 point) — Single-Layer Neural Network\n",
        "\n",
        "**Content:**  \n",
        "Train the simplest single-layer neural network on the MNIST dataset.  \n",
        "\n",
        "- **Goal:** Achieve the highest possible accuracy on the test set.  \n",
        "- **Notes:**  \n",
        "  - You may adjust training parameters (batch size, number of epochs, optimizer).  \n",
        "  - L2 regularization was tested: a small coefficient had negligible effect, while larger values significantly reduced accuracy.  \n",
        "\n",
        "---\n",
        "\n",
        "Example result (with tuned parameters):\n",
        "  ```\n",
        "  loss: 0.2865\n",
        "  acc: 0.9269\n",
        "  \n",
        "  val_loss: 0.2997\n",
        "  val_acc: 0.9232\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretive Note:  \n",
        "This baseline model achieved ~92–93% accuracy. It highlights the limitations of shallow networks and sets the stage for deeper architectures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI540zt_6V1h"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# --- Regularization coefficient ---\n",
        "l2_lambda = 0.0001\n",
        "\n",
        "# --- Input layer ---\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# --- Flatten image into vector ---\n",
        "flatten = Flatten()(input_image)\n",
        "\n",
        "# --- Single dense layer with softmax activation ---\n",
        "# Updated: use 'kernel_regularizer' instead of deprecated 'W_regularizer'\n",
        "dense_output = Dense(10,\n",
        "                     activation='softmax',\n",
        "                     kernel_regularizer=l2(l2_lambda))(flatten)\n",
        "\n",
        "# --- Build model ---\n",
        "model = Model(inputs=input_image, outputs=dense_output)\n",
        "\n",
        "# --- Compile model ---\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --- Train model ---\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=200,\n",
        "                    epochs=20,   # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# --- Evaluate model ---\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5KIm0b6V2X"
      },
      "source": [
        "## Task 2 (2 points) — Two-Layer Fully Connected Network\n",
        "\n",
        "**Content:**  \n",
        "In this task, we train a simple two‑layer fully connected neural network on the MNIST dataset.  \n",
        "- **Goal**: Improve accuracy compared to the single‑layer baseline (Task 1).  \n",
        "- **Note**:\n",
        "  - You are allowed to change training parameters (batch size, epochs, optimizer) to maximize test accuracy.  \n",
        "  \n",
        "---\n",
        "\n",
        "### Your test accuracy:\n",
        " `print(score[0], score[1])`\n",
        "\n",
        "Example result:  \n",
        "  ```\n",
        "  loss: 0.0855\n",
        "  accuracy: 0.9759\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretive Note:  \n",
        "Accuracy improved significantly (~97.6%) compared to Task 1, demonstrating the power of adding hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQXupbqT6V26"
      },
      "source": [
        "# --- Two-layer fully connected network ---\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Input layer\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# Flatten image into vector\n",
        "flatten = Flatten()(input_image)\n",
        "\n",
        "# First dense layer with ReLU activation\n",
        "dense1 = Dense(128, activation='relu')(flatten)\n",
        "\n",
        "# Output layer with softmax activation (10 classes)\n",
        "dense2 = Dense(10, activation='softmax')(dense1)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_image, outputs=dense2)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=200,\n",
        "                    epochs=20,       # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRmPpO3O6V3X"
      },
      "source": [
        "## Task 3 (2 points) — Three-Layer Fully Connected Network\n",
        "\n",
        "**Content:**  \n",
        "In this task, we train a three‑layer fully connected neural network on the MNIST dataset.  \n",
        "- **Goal**: Improve accuracy compared to the two‑layer model (Task 2).  \n",
        "- **Note**:\n",
        "  - You are allowed to change training parameters (batch size, epochs, optimizer) to maximize test accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### Your test accuracy:\n",
        " `print(score[0], score[1])`\n",
        "\n",
        "Example result:  \n",
        "  ```\n",
        "  loss: 0.0747  \n",
        "  accuracy: 0.9788\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretive Note:  \n",
        "Adding a third hidden layer increased accuracy to ~97.9%, showing diminishing returns compared to the two‑layer model but still a measurable improvement.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoAo5NaL6V38"
      },
      "source": [
        "# --- Three-layer fully connected network ---\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Input layer\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# Flatten image into vector\n",
        "flatten = Flatten()(input_image)\n",
        "\n",
        "# First dense layer with ReLU activation\n",
        "dense1 = Dense(960, activation='relu')(flatten)\n",
        "\n",
        "# Second dense layer with ReLU activation\n",
        "dense2 = Dense(160, activation='relu')(dense1)\n",
        "\n",
        "# Output layer with softmax activation (10 classes)\n",
        "dense3 = Dense(10, activation='softmax')(dense2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_image, outputs=dense3)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=100,\n",
        "                    epochs=10,       # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FjgSVm6V4W"
      },
      "source": [
        "## Task 4 (3 points) — Adding Normalization Layers\n",
        "\n",
        "**Content:**  \n",
        "In this task, we test whether the accuracy improves when adding normalization layers (such as Dropout, Batch Normalization, etc.) to the network.  \n",
        "- **Goal**: Compare results with previous tasks and observe the effect of these techniques on accuracy, loss, and convergence speed.\n",
        "\n",
        "---\n",
        "\n",
        "### Your test accuracy\n",
        "`print(score[0], score[1])`\n",
        "\n",
        "Example result:\n",
        "  ```\n",
        "  loss: 0.1652  \n",
        "  accuracy: 0.9816  \n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretive Note:  \n",
        "Accuracy improved with normalization, but loss increased. Convergence speed was faster, showing that normalization stabilizes training but may shift the balance between accuracy and loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFACDs5V6V41"
      },
      "source": [
        "# --- Fully connected network with normalization layers ---\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Regularization coefficient\n",
        "l2_lambda = 0.0001\n",
        "\n",
        "# Input layer\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# Flatten image into vector\n",
        "flatten = Flatten()(input_image)\n",
        "flatten = BatchNormalization(axis=1)(flatten)\n",
        "\n",
        "# First dense layer with ReLU activation + L2 regularization\n",
        "dense1 = Dense(1024, activation='relu',\n",
        "               kernel_regularizer=l2(l2_lambda))(flatten)\n",
        "dense1 = BatchNormalization(axis=1)(dense1)\n",
        "drop1 = Dropout(0.5)(dense1)\n",
        "\n",
        "# Second dense layer with ReLU activation + L2 regularization\n",
        "dense2 = Dense(128, activation='relu',\n",
        "               kernel_regularizer=l2(l2_lambda))(drop1)\n",
        "dense2 = BatchNormalization(axis=1)(dense2)\n",
        "drop2 = Dropout(0.5)(dense2)\n",
        "\n",
        "# Output layer with softmax activation\n",
        "dense3 = Dense(10, activation='softmax')(drop2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_image, outputs=dense3)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=250,\n",
        "                    epochs=50,       # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtfglgVy6V5O"
      },
      "source": [
        "## Task 5 (4 points) — Deep Fully Connected Network (No Convolutional Layers)\n",
        "\n",
        "**Content:**  \n",
        "In this task, we train a deep fully connected neural network (without convolutional layers) to achieve the best possible accuracy on the MNIST test set.  \n",
        "- **Goal**: Maximize test performance using deeper architectures, normalization, and dropout.\n",
        "- **Note**:\n",
        "  - There are no restrictions on the number of layers\n",
        "\n",
        "---\n",
        "\n",
        "### Your test accuracy\n",
        "`print(score[0], score[1])`\n",
        "\n",
        "Example result:\n",
        "  ```\n",
        "  loss: 0.0677  \n",
        "  accuracy: 0.9828\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretive Note:  \n",
        "Increasing depth and adding normalization/dropout improved accuracy to ~98.3%. However, deeper networks also increased training time and risk of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osDHwuFj6V5s"
      },
      "source": [
        "# --- Deep fully connected network (no convolutional layers) ---\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Input layer\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# Flatten image into vector + normalization\n",
        "flatten = Flatten()(input_image)\n",
        "flatten = BatchNormalization(axis=1)(flatten)\n",
        "\n",
        "# First dense block\n",
        "dense1 = Dense(1024, activation='relu')(flatten)\n",
        "dense1 = BatchNormalization(axis=1)(dense1)\n",
        "drop1 = Dropout(0.5)(dense1)\n",
        "\n",
        "# Second dense block\n",
        "dense12 = Dense(760, activation='relu')(drop1)\n",
        "dense12 = BatchNormalization(axis=1)(dense12)\n",
        "drop12 = Dropout(0.5)(dense12)\n",
        "\n",
        "# Third dense block\n",
        "dense22 = Dense(560, activation='relu')(drop12)\n",
        "dense22 = BatchNormalization(axis=1)(dense22)\n",
        "drop22 = Dropout(0.5)(dense22)\n",
        "\n",
        "# Fourth dense block\n",
        "dense2 = Dense(160, activation='relu')(drop22)\n",
        "dense2 = BatchNormalization(axis=1)(dense2)\n",
        "drop2 = Dropout(0.5)(dense2)\n",
        "\n",
        "# Output layer\n",
        "dense3 = Dense(10, activation='softmax')(drop2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_image, outputs=dense3)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=100,\n",
        "                    epochs=25,       # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o0-swCV6V6B"
      },
      "source": [
        "## Task 6 (3 points) — Network with One Convolutional Layer\n",
        "\n",
        "**Content:**  \n",
        "In this task, we train a neural network with a single convolutional layer to achieve the best possible accuracy on the MNIST test set.  \n",
        "- **Goal**: Compare performance with previous fully connected models and observe the effect of adding convolution.\n",
        "- **Note**:\n",
        "  - There are no restrictions on the total number of fully connected layers, and subsampling (pooling) layers can be used without limitation.   \n",
        "\n",
        "---\n",
        "\n",
        "### Your test accuracy\n",
        "`print(score[0], score[1])`\n",
        "\n",
        "Example result:\n",
        "  ```\n",
        "  loss: 0.0599  \n",
        "  accuracy: 0.9834\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretive Note:\n",
        "Adding a convolutional layer improved accuracy slightly compared to deep fully connected networks. The model also converged faster, showing the benefit of convolution for image data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRiJ5LrI6V6j"
      },
      "source": [
        "# --- Neural network with one convolutional layer ---\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Input layer\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# Initial pooling layer\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(input_image)\n",
        "\n",
        "# Convolutional block\n",
        "inp_norm = BatchNormalization(axis=1)(pool1)\n",
        "conv = Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "              padding='same', data_format='channels_first')(inp_norm)\n",
        "conv = BatchNormalization(axis=1)(conv)\n",
        "conv = Dropout(0.5)(conv)\n",
        "\n",
        "# Additional pooling\n",
        "pool = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv)\n",
        "\n",
        "# Flatten for dense layers\n",
        "flatten = Flatten()(pool)\n",
        "flatten = BatchNormalization(axis=1)(flatten)\n",
        "\n",
        "# Dense blocks\n",
        "dense1 = Dense(1024, activation='relu')(flatten)\n",
        "dense1 = BatchNormalization(axis=1)(dense1)\n",
        "drop1 = Dropout(0.5)(dense1)\n",
        "\n",
        "dense12 = Dense(760, activation='relu')(drop1)\n",
        "dense12 = BatchNormalization(axis=1)(dense12)\n",
        "drop12 = Dropout(0.5)(dense12)\n",
        "\n",
        "dense22 = Dense(560, activation='relu')(drop12)\n",
        "dense22 = BatchNormalization(axis=1)(dense22)\n",
        "drop22 = Dropout(0.5)(dense22)\n",
        "\n",
        "dense2 = Dense(160, activation='relu')(drop22)\n",
        "dense2 = BatchNormalization(axis=1)(dense2)\n",
        "drop2 = Dropout(0.5)(dense2)\n",
        "\n",
        "# Output layer\n",
        "dense3 = Dense(10, activation='softmax')(drop2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_image, outputs=dense3)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=300,\n",
        "                    epochs=25,       # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_xfhOg86V7D"
      },
      "source": [
        "## Task 7 (5 points) — Comparing Optimizers\n",
        "\n",
        "**Content:**  \n",
        "In this task, we train the best neural network architecture from previous experiments using different optimizers:  \n",
        "SGD, SGD + Momentum, SGD + NAG, AdaGrad, Adadelta, RMSprop, and Adam.  \n",
        "\n",
        "The goal is to determine:  \n",
        "- Which optimizer achieves the highest accuracy on the test set.  \n",
        "- Which optimizer converges the fastest during training.  \n",
        "\n",
        "---\n",
        "\n",
        "### Test accuracy with different optimizers\n",
        "```\n",
        "SGD                loss: 0.1443   accuracy: 0.9520  \n",
        "SGD + Momentum     loss: 0.0648   accuracy: 0.9800  \n",
        "SGD + NAG          loss: 0.0627   accuracy: 0.9800  \n",
        "AdaGrad            loss: 0.0562   accuracy: 0.9833  \n",
        "Adadelta           loss: 0.0553   accuracy: 0.9833  \n",
        "RMSprop            loss: 0.0760   accuracy: 0.9812  \n",
        "Adam               loss: 0.0636   accuracy: 0.9818  \n",
        "```\n",
        "**Best accuracy:** Adadelta (~98.3%)  \n",
        "**Fastest convergence:** Adadelta\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_QKxNym6V8A"
      },
      "source": [
        "# --- Best neural network architecture with optimizer comparison ---\n",
        "# Input layer\n",
        "input_image = Input(shape=(1, 28, 28))\n",
        "\n",
        "# Initial pooling\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(input_image)\n",
        "\n",
        "# Convolutional block\n",
        "inp_norm = BatchNormalization(axis=1)(pool1)\n",
        "conv = Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "              padding='same', data_format='channels_first')(inp_norm)\n",
        "conv = BatchNormalization(axis=1)(conv)\n",
        "conv = Dropout(0.5)(conv)\n",
        "\n",
        "# Additional pooling\n",
        "pool = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv)\n",
        "\n",
        "# Flatten for dense layers\n",
        "flatten = Flatten()(pool)\n",
        "flatten = BatchNormalization(axis=1)(flatten)\n",
        "\n",
        "# Dense blocks\n",
        "dense1 = Dense(1024, activation='relu')(flatten)\n",
        "dense1 = BatchNormalization(axis=1)(dense1)\n",
        "drop1 = Dropout(0.5)(dense1)\n",
        "\n",
        "dense12 = Dense(760, activation='relu')(drop1)\n",
        "dense12 = BatchNormalization(axis=1)(dense12)\n",
        "drop12 = Dropout(0.5)(dense12)\n",
        "\n",
        "dense22 = Dense(560, activation='relu')(drop12)\n",
        "dense22 = BatchNormalization(axis=1)(dense22)\n",
        "drop22 = Dropout(0.5)(dense22)\n",
        "\n",
        "dense2 = Dense(160, activation='relu')(drop22)\n",
        "dense2 = BatchNormalization(axis=1)(dense2)\n",
        "drop2 = Dropout(0.5)(dense2)\n",
        "\n",
        "# Output layer\n",
        "dense3 = Dense(10, activation='softmax')(drop2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_image, outputs=dense3)\n",
        "\n",
        "# Compile model with Adam optimizer (example)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_split=0.25,\n",
        "                    batch_size=300,\n",
        "                    epochs=25,       # updated argument name\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}